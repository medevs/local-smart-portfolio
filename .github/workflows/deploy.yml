name: Build & Push Portfolio Images

on:
  push:
    branches:
      - main

jobs:
  build-and-push:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Log in to GHCR
        uses: docker/login-action@v2
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GHCR_TOKEN }}

      # IMPORTANT: NEXT_PUBLIC_* vars are build-time only in Next.js!
      # They get embedded into the JS bundle during build.
      # Set NEXT_PUBLIC_API_URL secret in GitHub repo settings, or change the default below.
      # This should be the URL where users' browsers can reach the backend API.
      - name: Build frontend image
        run: |
          API_URL="${{ secrets.NEXT_PUBLIC_API_URL }}"
          if [ -z "$API_URL" ]; then
            API_URL="https://portfolio-api.medevs.local"
          fi
          echo "Building frontend with API_URL: ${API_URL}"
          docker build \
            --build-arg NEXT_PUBLIC_API_URL=${API_URL} \
            -t ghcr.io/${{ github.repository_owner }}/portfolio-frontend:latest \
            ./frontend

      - name: Build backend image
        run: |
          docker build -t ghcr.io/${{ github.repository_owner }}/portfolio-backend:latest ./backend

      - name: Push frontend image
        run: |
          docker push ghcr.io/${{ github.repository_owner }}/portfolio-frontend:latest

      - name: Push backend image
        run: |
          docker push ghcr.io/${{ github.repository_owner }}/portfolio-backend:latest

  deploy:
    runs-on: self-hosted
    needs: build-and-push
    if: github.ref == 'refs/heads/main'
    steps:
      - name: Deploy to homelab
        run: |
          set -e
          cd ~/projects/local-smart-portfolio

          echo "ðŸ“¦ Pulling latest code from GitHub..."
          git pull origin main

          echo "ðŸ“¥ Pulling latest GHCR images..."
          docker compose -f docker-compose.yml -f docker-compose.homelab.yml --profile observability pull

          echo "ðŸ”„ Recreating containers with homelab overrides..."
          # The ollama-init service will automatically pull required models
          # (llama3.2:3b for LLM, nomic-embed-text for embeddings)
          # --profile observability enables Langfuse tracing services
          docker compose -f docker-compose.yml -f docker-compose.homelab.yml --profile observability up -d --force-recreate

          echo "ðŸ“‹ Checking ollama-init logs..."
          docker compose -f docker-compose.yml -f docker-compose.homelab.yml --profile observability logs ollama-init || true

          echo "ðŸ§¹ Cleaning up old images..."
          docker image prune -f

          echo "âœ… Deployment complete!"
