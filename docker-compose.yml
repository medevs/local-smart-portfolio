# =============================================================================
# Docker Compose - AI Portfolio Application
# =============================================================================
# Development and Production-ready configuration
# =============================================================================

services:
  # ===========================================================================
  # Backend Service (FastAPI)
  # ===========================================================================
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: portfolio-backend
    restart: unless-stopped
    ports:
      - "8000:8000"
    environment:
      # Application Settings
      - APP_NAME=${APP_NAME:-AI Portfolio Backend}
      - APP_VERSION=${APP_VERSION:-1.0.0}
      - DEBUG=${DEBUG:-false}
      
      # Server Settings
      - HOST=0.0.0.0
      - PORT=8000
      
      # CORS Settings (comma-separated)
      - CORS_ORIGINS=${CORS_ORIGINS:-http://localhost:3000,http://localhost:3001}
      
      # Ollama LLM Settings
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://ollama:11434}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3.2:3b}
      
      # ChromaDB Settings
      - CHROMA_PERSIST_DIR=/app/data/chroma_db
      - CHROMA_COLLECTION_NAME=${CHROMA_COLLECTION_NAME:-portfolio_docs}
      
      # Document Processing
      - UPLOAD_DIR=/app/data/documents
      - MAX_FILE_SIZE_MB=${MAX_FILE_SIZE_MB:-10}
      - ALLOWED_EXTENSIONS=${ALLOWED_EXTENSIONS:-.pdf,.md,.txt,.docx}
      
      # RAG Settings
      - CHUNK_SIZE=${CHUNK_SIZE:-500}
      - CHUNK_OVERLAP=${CHUNK_OVERLAP:-50}
      - TOP_K_RESULTS=${TOP_K_RESULTS:-3}
      
      # Embedding Model
      - EMBEDDING_MODEL=${EMBEDDING_MODEL:-all-MiniLM-L6-v2}
      
      # Security (REQUIRED - set in .env file)
      - ADMIN_API_KEY=${ADMIN_API_KEY}
    volumes:
      # Persist ChromaDB data
      - chroma_data:/app/data/chroma_db
      # Persist uploaded documents
      - documents_data:/app/data/documents
      # Persist logs
      - backend_logs:/app/logs
    networks:
      - portfolio-network
    depends_on:
      - ollama
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # ===========================================================================
  # Frontend Service (Next.js)
  # ===========================================================================
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: portfolio-frontend
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      # Backend API URL (internal Docker network)
      - NEXT_PUBLIC_API_URL=${NEXT_PUBLIC_API_URL:-http://backend:8000}
      # Admin API Key (for frontend admin operations)
      - NEXT_PUBLIC_ADMIN_API_KEY=${ADMIN_API_KEY}
    networks:
      - portfolio-network
    depends_on:
      backend:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3000', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # ===========================================================================
  # Ollama Service (Local LLM)
  # ===========================================================================
  ollama:
    image: ollama/ollama:latest
    container_name: portfolio-ollama
    restart: unless-stopped
    ports:
      - "11434:11434"
    volumes:
      # Persist Ollama models
      - ollama_data:/root/.ollama
    networks:
      - portfolio-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    # Optional: Set resource limits
    deploy:
      resources:
        limits:
          memory: 8G
        reservations:
          memory: 4G

# =============================================================================
# Volumes (Data Persistence)
# =============================================================================
volumes:
  chroma_data:
    driver: local
  documents_data:
    driver: local
  backend_logs:
    driver: local
  ollama_data:
    driver: local

# =============================================================================
# Networks
# =============================================================================
networks:
  portfolio-network:
    driver: bridge

