# ğŸš€ AI-Powered Portfolio Website

A modern, self-hosted portfolio website with an AI assistant powered by local LLMs and RAG technology.

<div align="center">

![Next.js](https://img.shields.io/badge/Next.js-15.5.5-black?style=for-the-badge&logo=next.js)
![FastAPI](https://img.shields.io/badge/FastAPI-0.115.0-green?style=for-the-badge&logo=fastapi)
![TypeScript](https://img.shields.io/badge/TypeScript-5.0-blue?style=for-the-badge&logo=typescript)
![Python](https://img.shields.io/badge/Python-3.11+-blue?style=for-the-badge&logo=python)

*Showcase your work with a beautiful portfolio and intelligent AI assistant*

</div>

---

## âœ¨ Features

- **ğŸ¨ Modern Portfolio**: Beautiful, responsive design showcasing projects, skills, and experience
- **ğŸ¤– AI Assistant**: Local LLM-powered chatbot with RAG for intelligent responses
- **ğŸ”’ Privacy-First**: All AI processing happens locally - no data leaves your server
- **ğŸ“Š Real-time Metrics**: Display live system status and LLM performance benchmarks
- **ğŸ“± Fully Responsive**: Mobile-first design that works on all devices

---

## ğŸ› ï¸ Tech Stack

### Frontend
- **Framework**: Next.js 15.5.5 (App Router)
- **Language**: TypeScript
- **Styling**: TailwindCSS 4.0
- **UI Components**: shadcn/ui + Radix UI
- **Animations**: Framer Motion
- **Icons**: Lucide React + React Icons

### Backend
- **Framework**: FastAPI 0.115.0
- **Language**: Python 3.11+
- **Vector DB**: ChromaDB
- **LLM**: Ollama (local models)
- **Embeddings**: sentence-transformers

---

## ğŸš€ Quick Start

### Prerequisites

- **Docker** and **Docker Compose** (recommended)
- OR **Python 3.11+**, **Node.js 18+**, and **Ollama** for local development

---

## ğŸ³ Docker Deployment (Recommended)

### Step 1: Clone the Repository

```bash
git clone https://github.com/medevs/local-smart-portfolio.git
cd local-smart-portfolio
```

### Step 2: Configure Environment Variables

Create a `backend/.env` file:

```bash
cd backend
cp .env.example .env  # If .env.example exists
# OR create .env manually
```

Edit `backend/.env`:

```env
# Ollama Configuration
OLLAMA_BASE_URL=http://ollama:11434
OLLAMA_MODEL=llama3.2:3b

# ChromaDB Configuration
CHROMA_PERSIST_DIR=./data/chroma_db
CHROMA_COLLECTION_NAME=portfolio_docs

# Security (REQUIRED - Generate a secure key)
ADMIN_API_KEY=your-secure-api-key-here

# CORS Settings (comma-separated)
CORS_ORIGINS=http://localhost:3000,http://localhost:3001

# Optional: Other settings
DEBUG=false
```

**Generate a secure API key:**

```bash
# Using Python
python -c "import secrets; print(secrets.token_urlsafe(32))"

# OR using OpenSSL
openssl rand -base64 32
```

### Step 3: Configure Frontend

Create `frontend/.env.local` (for local development without Docker):

```env
NEXT_PUBLIC_API_URL=http://localhost:8000
NEXT_PUBLIC_ADMIN_API_KEY=your-admin-api-key-here
```

> **Note for Docker users**: `NEXT_PUBLIC_API_URL` is already configured as a build argument in `docker-compose.yml`. The `.env.local` file is only needed for local development without Docker.

### Step 4: Start Services

```bash
# Build and start all services
docker compose up -d

# Check service status
docker compose ps
```

### Step 5: Initialize Ollama Model

```bash
# Download the LLM model (this may take 5-15 minutes, ~2GB)
docker compose exec ollama ollama pull llama3.2:3b
```

### Step 6: Access the Application

- **Portfolio**: http://localhost:3000
- **Admin Dashboard**: http://localhost:3000/admin
- **Backend API**: http://localhost:8000
- **API Documentation**: http://localhost:8000/docs
- **Health Check**: http://localhost:8000/health

---

## ğŸ’» Local Development (Without Docker)

### Backend Setup

```bash
# Navigate to backend
cd backend

# Create virtual environment
python -m venv venv

# Activate virtual environment
# Linux/Mac:
source venv/bin/activate
# Windows:
venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Create .env file (see Docker section above)
# Then start the server
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

### Frontend Setup

```bash
# Navigate to frontend
cd frontend

# Install dependencies
pnpm install
# OR
npm install

# Create .env.local file (see Docker section above)
# Then start the development server
pnpm dev
# OR
npm run dev
```

### Start Ollama

```bash
# Install Ollama from https://ollama.ai
# Then start the service
ollama serve

# Download the model
ollama pull llama3.2:3b
```

---

## ğŸ“ Project Structure

```
local-smart-portfolio/
â”œâ”€â”€ backend/              # FastAPI backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ routers/      # API endpoints
â”‚   â”‚   â”œâ”€â”€ services/     # Business logic
â”‚   â”‚   â”œâ”€â”€ models/       # Pydantic models
â”‚   â”‚   â””â”€â”€ utils/        # Utilities
â”‚   â”œâ”€â”€ data/             # ChromaDB and document storage
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ frontend/             # Next.js frontend
â”‚   â”œâ”€â”€ app/              # Next.js app router pages
â”‚   â”œâ”€â”€ components/       # React components
â”‚   â”œâ”€â”€ data/             # Static data files (customize these!)
â”‚   â”œâ”€â”€ lib/              # Utilities & API client
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ docker-compose.yml     # Docker configuration
â”œâ”€â”€ docker-compose.prod.yml # Production overrides
â””â”€â”€ README.md
```

---

## ğŸ¯ Customization

### Update Personal Information

Edit `frontend/data/personal.ts` with your information:
- Personal details (name, email, location, bio)
- Work experience
- Education
- Skills
- Social media links

### Update Portfolio Content

- **Projects**: `frontend/data/projects.ts`
- **Timeline**: `frontend/data/timeline.ts`
- **Skills**: `frontend/data/skills.tsx`
- **Page Content**: `frontend/data/pageContent.ts`
- **About Section**: `frontend/data/about.tsx`

### Frontend Styling Customization

The portfolio uses TailwindCSS with a custom amber/gold theme. To customize:

1. **Global Styles**: Edit `frontend/app/globals.css`
2. **Color Variables**: Update CSS custom properties
3. **Components**: Modify Tailwind classes in component files
4. **Theme**: Adjust colors in `frontend/components/layout/ClientLayout.tsx`

### Customize Styling

The portfolio uses an amber/gold color scheme. To customize:

1. **Global Styles**: Edit `frontend/app/globals.css`
2. **Color Variables**: Update CSS custom properties
3. **Components**: Modify Tailwind classes in component files
4. **Theme**: Adjust colors in `frontend/components/layout/ClientLayout.tsx`

### Change AI Model

To use a different Ollama model:

1. Update `OLLAMA_MODEL` in `backend/.env`
2. Pull the new model: `docker compose exec ollama ollama pull <model-name>`
3. Restart the backend: `docker compose restart backend`

---

## ğŸ”§ Docker Commands

```bash
# Start all services
docker compose up -d

# Stop all services
docker compose down

# View logs
docker compose logs -f

# View logs for specific service
docker compose logs -f backend
docker compose logs -f frontend

# Restart a service
docker compose restart backend

# Rebuild and restart
docker compose up -d --build

# Check service status
docker compose ps

# Execute commands in containers
docker compose exec backend bash
docker compose exec frontend sh
```

---

## ğŸš€ Production Deployment

### Using Production Override

For production, use the production override:

```bash
docker compose -f docker-compose.yml -f docker-compose.prod.yml up -d
```

The production configuration:
- Removes port mappings (use a reverse proxy)
- Sets resource limits
- Disables debug mode
- Includes Nginx reverse proxy (optional)

### Using a Reverse Proxy

Recommended reverse proxies:
- **Nginx**
- **Traefik**
- **Caddy**

Example Nginx configuration is available in `infra/nginx/`.

### Homelab CI/CD Deployment (Optional)

If you have CI/CD set up with GitHub Actions that builds and pushes images to GHCR:

```bash
# Using the root file (for backward compatibility)
docker compose -f docker-compose.yml -f docker-compose.homelab.yml up -d

# OR using the organized deployment/ folder
docker compose -f docker-compose.yml -f deployment/docker-compose.homelab.yml up -d
```

**Note**: Both files are identical. The root version is kept for backward compatibility with existing deployments.

**What it does**:
- Uses pre-built images from GHCR instead of building locally
- Configures homelab-specific ports and environment variables
- Sets `pull_policy: always` to automatically get latest images

**Update image names**: Edit the `image:` fields to match your own GHCR registry if using this template.

---

## ğŸ’» Frontend Development

### Local Development Setup

```bash
cd frontend

# Install dependencies
pnpm install  # or npm install

# Run development server
pnpm dev
```

Open [http://localhost:3000](http://localhost:3000) to view the portfolio.

### Frontend Project Structure

```
frontend/
â”œâ”€â”€ app/                  # Next.js app router pages
â”‚   â”œâ”€â”€ page.tsx         # Home page
â”‚   â”œâ”€â”€ about/           # About page
â”‚   â”œâ”€â”€ projects/        # Projects page
â”‚   â”œâ”€â”€ contact/         # Contact page
â”‚   â”œâ”€â”€ homelab/         # Homelab journey page (optional)
â”‚   â””â”€â”€ admin/           # Admin dashboard
â”‚
â”œâ”€â”€ components/          # React components
â”‚   â”œâ”€â”€ ui/              # shadcn/ui components
â”‚   â”œâ”€â”€ sections/        # Page sections
â”‚   â”œâ”€â”€ layout/          # Layout components
â”‚   â””â”€â”€ chat/            # Chat components
â”‚
â”œâ”€â”€ data/                # Static data files (customize these!)
â”‚   â”œâ”€â”€ personal.ts      # Personal information
â”‚   â”œâ”€â”€ projects.ts      # Projects data
â”‚   â”œâ”€â”€ timeline.ts      # Timeline data
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ lib/                 # Utilities
    â”œâ”€â”€ api.ts           # API client
    â””â”€â”€ utils.ts         # Helper functions
```

### Frontend Environment Variables

Create `frontend/.env.local`:

```env
NEXT_PUBLIC_API_URL=http://localhost:8000
NEXT_PUBLIC_ADMIN_API_KEY=your-admin-api-key  # Optional, for admin panel
```

### Frontend Available Scripts

```bash
# Development
pnpm dev              # Start dev server

# Production
pnpm build            # Build for production
pnpm start            # Start production server

# Code Quality
pnpm lint             # Run ESLint
pnpm type-check       # TypeScript type checking
```

### Frontend Dependencies

**Core**:
- Next.js 15.5.5 - React framework
- TypeScript - Type safety
- TailwindCSS 4.0 - Styling
- Framer Motion - Animations

**UI Components**:
- shadcn/ui - Component library
- Radix UI - Accessible primitives
- Lucide React - Icons
- React Icons - Additional icons

**State & Data**:
- Zustand - State management
- Axios - HTTP client

---

## ğŸ”§ API Endpoints

### Health Check
```http
GET /health
```

### Chat (Streaming)
```http
POST /chat/stream
Content-Type: application/json

{
  "message": "Tell me about your projects",
  "history": []
}
```

### Document Upload (RAG)
```http
POST /ingest
Content-Type: multipart/form-data
X-Admin-Key: <your-api-key>

file: <document-file>
```

### Admin Operations

**Get Statistics:**
```http
GET /admin/stats
X-Admin-Key: <your-api-key>
```

**List Documents:**
```http
GET /documents
X-Admin-Key: <your-api-key>
```

**Delete Document:**
```http
DELETE /documents/{id}
X-Admin-Key: <your-api-key>
```

---

## ğŸ”’ Security Notes

1. **API Key**: Always use a strong, randomly generated API key
2. **Environment Variables**: Never commit `.env` files to version control
3. **CORS**: Configure `CORS_ORIGINS` properly for production
4. **Reverse Proxy**: Use HTTPS in production with a reverse proxy
5. **Firewall**: Restrict access to admin endpoints

---

## ğŸ› Troubleshooting

### Services won't start

```bash
# Check logs
docker compose logs

# Check if ports are in use
netstat -tulpn | grep -E ':(3000|8000|11434)'

# Rebuild containers
docker compose up -d --build
```

### Ollama model not loading

```bash
# Check Ollama logs
docker compose logs ollama

# Manually pull the model
docker compose exec ollama ollama pull llama3.2:3b

# List available models
docker compose exec ollama ollama list
```

### Frontend can't connect to backend

1. **Docker users**: `NEXT_PUBLIC_API_URL` must be passed as a **build argument**, not a runtime environment variable. Check your `docker-compose.yml`:
   ```yaml
   frontend:
     build:
       args:
         - NEXT_PUBLIC_API_URL=http://localhost:8000  # Must be build arg!
   ```
   Then rebuild: `docker compose build frontend --no-cache && docker compose up -d`

2. **Local development**: Check `NEXT_PUBLIC_API_URL` in `frontend/.env.local`
3. Verify backend is running: `docker compose ps`
4. Check CORS settings in `backend/.env`
5. Check browser console for errors

**Why `localhost` instead of `backend`?** The frontend JavaScript runs in your browser, which cannot resolve Docker's internal hostnames like `backend`. Use `http://localhost:8000` since port 8000 is exposed to your host machine.

### ChromaDB issues

```bash
# Reset ChromaDB (WARNING: Deletes all data)
docker compose down
docker volume rm portfolio_chroma_data
docker compose up -d
```

---

## ğŸ“š Additional Resources

- [Next.js Documentation](https://nextjs.org/docs)
- [FastAPI Documentation](https://fastapi.tiangolo.com)
- [Ollama Documentation](https://ollama.ai/docs)
- [ChromaDB Documentation](https://docs.trychroma.com)

---

## ğŸ¤ Contributing

This is an open-source portfolio template. Feel free to:

1. Fork the repository
2. Customize it for your own use
3. Submit improvements via Pull Requests

---

## ğŸ“„ License

MIT License - feel free to use this for your own portfolio!

---

## ğŸ™ Acknowledgments

- **Ollama** for local LLM inference
- **ChromaDB** for vector database
- **shadcn/ui** for beautiful components
- **Next.js** and **FastAPI** teams

---

<div align="center">

**Built with â¤ï¸ using modern web technologies and AI**

</div>
# Test SSH fix
